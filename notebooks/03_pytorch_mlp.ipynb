{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorch MLP Implementation\n",
        "\n",
        "This notebook demonstrates the PyTorch implementation of a Multi-layer Perceptron for MNIST digit classification, including training, validation, and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "from pytorch_mlp import MNISTCustomDataset, CustomMLP, train, validate, report_accuracy, compute_confusion_matrix\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "data_dir = '../data'\n",
        "train_dataset = MNISTCustomDataset(os.path.join(data_dir, 'training'), transform=transform)\n",
        "val_dataset = MNISTCustomDataset(os.path.join(data_dir, 'validation'), transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of classes: 10\")\n",
        "print(f\"Image size: 28x28 pixels\")\n",
        "print(f\"Input features: 784 (28*28)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = CustomMLP(input_size=784, output_size=10, dropout_rate=0.1)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print(f\"Training for {num_epochs} epochs...\")\n",
        "print(\"Epoch\\tTrain Loss\\tVal Loss\\tVal Acc\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, loss_function, device)\n",
        "    val_loss, val_acc = validate(model, val_loader, loss_function, device)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    print(f\"{epoch+1}\\t{train_loss:.4f}\\t\\t{val_loss:.4f}\\t\\t{val_acc:.2f}%\")\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Best validation accuracy: {max(val_accuracies):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training progress\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot training and validation loss\n",
        "epochs = range(1, num_epochs + 1)\n",
        "ax1.plot(epochs, train_losses, label='Training Loss', marker='o', linewidth=2)\n",
        "ax1.plot(epochs, val_losses, label='Validation Loss', marker='s', linewidth=2)\n",
        "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot validation accuracy\n",
        "ax2.plot(epochs, val_accuracies, label='Validation Accuracy', marker='o', linewidth=2, color='green')\n",
        "ax2.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        predictions = model(images)\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        \n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "confusion_matrix = compute_confusion_matrix(all_predictions, all_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(10)\n",
        "plt.xticks(tick_marks, tick_marks)\n",
        "plt.yticks(tick_marks, tick_marks)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# Add text annotations\n",
        "thresh = confusion_matrix.max() / 2.\n",
        "for i, j in np.ndindex(confusion_matrix.shape):\n",
        "    plt.text(j, i, format(confusion_matrix[i, j], 'd'),\n",
        "            ha=\"center\", va=\"center\",\n",
        "            color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate per-class accuracy\n",
        "print(\"\\nPer-class accuracy:\")\n",
        "for i in range(10):\n",
        "    class_correct = confusion_matrix[i, i]\n",
        "    class_total = confusion_matrix[i, :].sum()\n",
        "    accuracy = class_correct / class_total * 100\n",
        "    print(f\"Class {i}: {accuracy:.2f}% ({class_correct}/{class_total})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
